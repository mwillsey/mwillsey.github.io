---
layout: paper
title: "Equality Saturation for Tensor Graph Superoptimization"
shorttitle: tensat

type: "publication"
authors: [yichen, mangpo, remy, mwillsey, sudip, jpienaar]
venue: "MLSys 2021"
venue_url: "https://mlsys.org/Conferences/2021"

links:
  arXiv: "https://arxiv.org/abs/2101.01332"
  proceedings: "https://proceedings.mlsys.org/paper/2021/hash/65ded5353c5ee48d0b7d48c591b8f430-Abstract.html"

bib: |
  @inproceedings{yang2021equality,
    title={Equality Saturation for Tensor Graph Superoptimization},
    author={Yichen Yang and Phitchaya Mangpo Phothilimtha and Yisu Remy Wang and Max Willsey and Sudip Roy and Jacques Pienaar},
    eprint={2101.01332},
    booktitle={Proceedings of Machine Learning and Systems},
    year={2021}
  }
style: |
  table {
    margin: auto;
    caption-side: bottom;
    border-collapse: collapse;
    tr:nth-child(2n+3) { background: #CCC9 };
    th,td { padding: .1em .6em; text-align: right };
    th:first-child { text-align: left };
  }
---


<table>
  <col>
  <colgroup span="2"></colgroup>
  <colgroup span="2"></colgroup>
  <tr>
    <td></td>             <th colspan="2">Search Time (sec)</th>  <th colspan="2">Runtime Speedup (%)</th>
  </tr>
  <tr>
    <td></td>             <th>TASO</th>  <th>Tensat</th>      <th>TASO</th>       <th>Tensat</th>
  </tr>
  <tr>
    <th>BERT</th>         <td>13.6</td>  <td><b>1.4</b></td>  <td>8.5</td>        <td><b>9.2</b></td>
  </tr>
  <tr>
    <th>ResNeXt-50</th>   <td>25.3</td>  <td><b>0.7</b></td>  <td>5.5</td>        <td><b>8.8</b></td>
  </tr>
  <tr>
    <th>NasNet-A</th>     <td>1226</td>  <td><b>10.6</b></td> <td>1.9</td>        <td><b>7.3</b></td>
  </tr>
  <tr>
    <th>NasRNN</th>       <td>177.3</td> <td><b>0.5</b></td>  <td>45.4</td>       <td><b>68.9</b></td>
  </tr>
  <tr>
    <th>Inception-v3</th> <td>68.6</td>  <td><b>5.1</b></td>  <td>6.3</td>        <td><b>10.0</b></td>
  </tr>
  <tr>
    <th>SqueezeNet</th>   <td>16.4</td>  <td><b>0.3</b></td>  <td>6.7</td>        <td><b>24.5</b></td>
  </tr>
  <tr>
    <th>VGG-19</th>       <td>8.9</td>   <td><b>0.4</b></td>  <td><b>8.9</b></td> <td><b>8.9</b></td>
  </tr>
  <caption style="margin: 1em">
  Compared to a previous state-of-the-art tool
  (<a href="https://dl.acm.org/doi/10.1145/3341301.3359630">TASO</a>, Jia et. al. 2019),
  Tensat can find up to 16% better optimizations in 48x less time on average.
  </caption>
</table>

## Abstract

One of the major optimizations employed in deep learning frameworks is
graph rewriting.
Production frameworks rely on heuristics to decide if rewrite rules
should be applied and in which order.
Prior research has shown that one can discover more optimal tensor
computation graphs if we search for a better sequence of substitutions
instead of relying on heuristics.
However, we observe that existing approaches for tensor graph
superoptimization both in production and research frameworks apply
substitutions in a sequential manner.
Such sequential search methods are sensitive to the order in which the
substitutions are applied and often only explore a small fragment of
the exponential space of equivalent graphs.
This paper presents a novel technique for tensor graph
superoptimization that employs equality saturation to apply all
possible substitutions at once.
We show that our approach can find optimized graphs with up to 16%
speedup over state-of-the-art, while spending on average 48x less time
optimizing.
